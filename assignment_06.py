# -*- coding: utf-8 -*-
"""assignment_06.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZGrzHEYDFSOBFdnCgcEoUWnJBl3Gf6K_
"""

import pandas as pd

# Q1. Load your dataset into python using the pandas library and save data into a
# dataframe named dfi (where i is one of your datasets, for a total of 4).

csv_path1 = 'resources/electric_cars.csv'
df1 = pd.read_csv(csv_path1, encoding="utf-8")
df1.head()

csv_path2 = 'resources/kobe.csv'
df2 = pd.read_csv(csv_path2, encoding="utf-8")
df2.head()

csv_path3 = 'resources/purchase_data.csv'
df3 = pd.read_csv(csv_path3, encoding="utf-8")
df3.head()

csv_path4 = 'resources/weather.csv'
df4 = pd.read_csv(csv_path4, encoding="utf-8")
df4.head()

# Q2. Preview your data by calling your dataframeâ€™s name. How many columns and rows do you see?

df1.info()
df2.info()
df3.info()
df4.info()

# Q3. Examine the shape of your data using the .shape command and the data types of
# your columns using .dtypes.

df1.shape
df2.shape
df3.shape
df4.shape

df1.dtypes

df2.dtypes

df3.dtypes

df4.dtypes

# Q4. Use .describe() on your data. What do you notice about your data? What does this
# command return?

# Ans: It returns the statistical summary analysis of each column in the dataframe.

df1.describe()

df2.describe()

df3.describe()

df4.describe()

# Q5. Use the .head() and .tail() command - what does this do?

# Ans: .head() fetches the first 5 rows in the dataframe.
# .tail() fetches the last 5 rows in the dataframe.

df1.head()

df1.tail()

df2.head()

df2.tail()

df3.head()

df3.tail()

df4.head()

df4.tail()

"""**## Extra Credit (3 pts):**"""

# list(df3 columns) or
list(df3.columns)

# 1. Choose one of your datasets and remove the header information. (Can delete
# the row in excel, etc..)

# Ans: In this DataFrame, the original header of the input CSV has been ignored, and the first row of the input data has been set as a header.
# One metod is: header = False
# and another is: skiprows = 1

csv_path = 'resources/weather.csv'
df3 = pd.read_csv(csv_path4, encoding="utf-8", skiprows = 1)

# 2. Import the data into your environment using pandas. Display the .head() of your
# data showing no header information.

df3.head()

# 3. Using pandas, update the dataset to include the header information. Display the
# updated data using .head().

# adding column name to the respective columns
df3.columns = [
  'index',
 'origin',
 'year',
 'month',
 'day',
 'hour',
 'temp',
 'dewp',
 'humid',
 'wind_dir',
 'wind_speed',
 'wind_gust',
 'precip',
 'pressure',
 'visib']

df3.head()

"""**## Extra Credit (3 pts)**
## Data Wrangling:
"""

# 3. Using pandas, update the dataset to include the header information. Display the
# updated data using .head().
csv_path = 'resources/atu_dirty.csv'
dirty_df = pd.read_csv(csv_path, encoding="utf-8")
dirty_df.head()

dirty_df.info()

"""**## atu_dirty Documentation:**
American Time Use Survey Data Sample - Dirty
Description
A dataset containing a subset of variables from the American Time Use Survey. This dataset is "dirty", meaning it has elements which require formatting before use.

Usage
data(atu_dirty)
Format
A data frame with 10,493 observations of 8 variables

Details
caseid. unique identifier of individual survey participant

V1. the age of the respondent

V2. the gender of the respondent (1: Male, 2: Female)

V3. the employment status of the respondent

V4. does the respondent have a physical difficulty (1: Person did not report having a physical difficulty, 2: Person surveyed reported the have a physical difficulty)

V5. the length of time the person sleeps, in minutes

V6. How long the respondent spent on homework assignments, in minutes

V7. the number of minutes the respondent spent socializing
"""

# Dropping the "unnamed: 0" column

dirty_df = dirty_df.drop("Unnamed: 0",axis=1)

dirty_df.head()

# Assigning column names
dirty_df.columns = ["case_id", "age", "gender", "employment_status", "physical_difficulty", "sleep_time(min)", "hw_time_spent(min)", "socializing_time(min)"]
dirty_df.head()

# To convert column values to lower case

dirty_df['employment_status'] = dirty_df['employment_status'].str.lower()

dirty_df.head()

dirty_df.info()

# Checking null values. Using isnull() function 
dirty_df.isnull()

# using isnull() function 
dirty_df.describe()